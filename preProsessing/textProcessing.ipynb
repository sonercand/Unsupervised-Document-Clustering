{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Text Preprocessing\n",
    "\n",
    "     Load merged job search results\n",
    "     load word to vector model (downloaded from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit)\n",
    "     remove stop words from description field\n",
    "     for each word in a given description fetch word vector size of 300\n",
    "     add a new column to the dataframe to keep word vectors\n",
    "     save pickles\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '..\\data'\n",
    "df = pd.read_parquet(path+'\\\\data_scientist_merged_01_09_2019.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sismc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sismc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import nltk\n",
    "import itertools\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "\n",
    "\n",
    "tokenizer1 = ToktokTokenizer()\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    text = re.sub(pattern, \", \",text)\n",
    "    tokens = tokenizer1.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desc'] = df.apply(lambda x: remove_stopwords(x['description']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(path+'\\\\GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVector(str):\n",
    "     if str in model:\n",
    "            return model[str]\n",
    "     else:\n",
    "            return None\n",
    "        \n",
    "def isInModel(str):\n",
    "     return str in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2202 16835\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(df.desc))\n",
    "print(tokenizer.document_count,len(tokenizer.word_counts))\n",
    "\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(df.desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = np.max([len(item)for item in list_tokenized_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = getVector(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SImple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2202, 1049)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense,Conv1D,MaxPooling1D,UpSampling1D,Embedding,LSTM,Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "input_ = Input(shape=(X_t[1].shape))\n",
    "x = Embedding(vocab_size, embed_size, weights=[embedding_matrix], trainable=True)(input_)\n",
    "x = Flatten()(x)\n",
    "encoded = Dense(units=128, activation='relu')(x)\n",
    "encoded = Dense(units=64, activation='relu')(encoded)\n",
    "encoded = Dense(units=32, activation='relu')(encoded)\n",
    "decoded = Dense(units=64, activation='relu')(encoded)\n",
    "decoded = Dense(units=X_t[1].shape[0], activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 1049)              0         \n",
      "_________________________________________________________________\n",
      "embedding_15 (Embedding)     (None, 1049, 300)         5050800   \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 314700)            0         \n",
      "=================================================================\n",
      "Total params: 5,050,800\n",
      "Trainable params: 5,050,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed = Model(input_,x)\n",
    "embed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 1049)              0         \n",
      "_________________________________________________________________\n",
      "embedding_15 (Embedding)     (None, 1049, 300)         5050800   \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 314700)            0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 128)               40281728  \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1049)              68185     \n",
      "=================================================================\n",
      "Total params: 45,413,161\n",
      "Trainable params: 45,413,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder=Model(input_, decoded)\n",
    "encoder = Model(input_, encoded)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 1049)              0         \n",
      "_________________________________________________________________\n",
      "embedding_15 (Embedding)     (None, 1049, 300)         5050800   \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 314700)            0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 128)               40281728  \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 45,342,864\n",
      "Trainable params: 45,342,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1761 samples, validate on 441 samples\n",
      "Epoch 1/50\n",
      "1761/1761 [==============================] - 15s 8ms/step - loss: -424.8254 - accuracy: 0.3190 - val_loss: -2288.9244 - val_accuracy: 0.2657\n",
      "Epoch 2/50\n",
      "1761/1761 [==============================] - 10s 5ms/step - loss: -7683.3954 - accuracy: 0.2224 - val_loss: -23313.9068 - val_accuracy: 0.1740\n",
      "Epoch 3/50\n",
      "1761/1761 [==============================] - 10s 6ms/step - loss: -52571.9243 - accuracy: 0.1470 - val_loss: -128615.9223 - val_accuracy: 0.1107\n",
      "Epoch 4/50\n",
      "1761/1761 [==============================] - 10s 6ms/step - loss: -244839.1926 - accuracy: 0.0939 - val_loss: -535418.5459 - val_accuracy: 0.0955\n",
      "Epoch 5/50\n",
      "1761/1761 [==============================] - 10s 6ms/step - loss: -920087.5085 - accuracy: 0.0867 - val_loss: -1877261.3622 - val_accuracy: 0.1012\n",
      "Epoch 6/50\n",
      "1761/1761 [==============================] - 10s 6ms/step - loss: -3034691.4634 - accuracy: 0.0887 - val_loss: -5795441.8424 - val_accuracy: 0.1194\n",
      "Epoch 7/50\n",
      "1761/1761 [==============================] - 11s 6ms/step - loss: -8858707.2027 - accuracy: 0.1186 - val_loss: -16110389.3628 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -23519990.5088 - accuracy: 0.0994 - val_loss: -41008510.1043 - val_accuracy: 0.1031\n",
      "Epoch 9/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -57539134.2692 - accuracy: 0.1166 - val_loss: -96667095.6735 - val_accuracy: 0.0955\n",
      "Epoch 10/50\n",
      "1761/1761 [==============================] - 16s 9ms/step - loss: -130957340.9199 - accuracy: 0.1200 - val_loss: -213038078.6576 - val_accuracy: 0.1032\n",
      "Epoch 11/50\n",
      "1761/1761 [==============================] - 16s 9ms/step - loss: -279475625.4310 - accuracy: 0.0972 - val_loss: -442610245.1519 - val_accuracy: 0.1108\n",
      "Epoch 12/50\n",
      "1761/1761 [==============================] - 18s 11ms/step - loss: -569339498.5576 - accuracy: 0.1124 - val_loss: -872711410.2132 - val_accuracy: 0.1298\n",
      "Epoch 13/50\n",
      "1761/1761 [==============================] - 16s 9ms/step - loss: -1100068299.3027 - accuracy: 0.1405 - val_loss: -1643460958.0408 - val_accuracy: 0.1155\n",
      "Epoch 14/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -2022758161.7354 - accuracy: 0.1120 - val_loss: -2968234029.8594 - val_accuracy: 0.1050\n",
      "Epoch 15/50\n",
      "1761/1761 [==============================] - 15s 9ms/step - loss: -3583674825.9216 - accuracy: 0.1210 - val_loss: -5163933503.2744 - val_accuracy: 0.0973\n",
      "Epoch 16/50\n",
      "1761/1761 [==============================] - 16s 9ms/step - loss: -6134177891.7252 - accuracy: 0.1185 - val_loss: -8685685736.7800 - val_accuracy: 0.1213\n",
      "Epoch 17/50\n",
      "1761/1761 [==============================] - 15s 8ms/step - loss: -10163970025.3220 - accuracy: 0.1113 - val_loss: -14167473286.6757 - val_accuracy: 0.1308\n",
      "Epoch 18/50\n",
      "1761/1761 [==============================] - 20s 11ms/step - loss: -16364398176.8177 - accuracy: 0.1129 - val_loss: -22485158468.4989 - val_accuracy: 0.1460\n",
      "Epoch 19/50\n",
      "1761/1761 [==============================] - 16s 9ms/step - loss: -25631791035.3844 - accuracy: 0.1444 - val_loss: -34820033872.6893 - val_accuracy: 0.1203\n",
      "Epoch 20/50\n",
      "1761/1761 [==============================] - 18s 10ms/step - loss: -39314328318.4009 - accuracy: 0.1089 - val_loss: -52681706646.9297 - val_accuracy: 0.1260\n",
      "Epoch 21/50\n",
      "1761/1761 [==============================] - 16s 9ms/step - loss: -58899105686.1692 - accuracy: 0.1299 - val_loss: -78071798823.4739 - val_accuracy: 0.1327\n",
      "Epoch 22/50\n",
      "1761/1761 [==============================] - 16s 9ms/step - loss: -86684492041.1584 - accuracy: 0.1262 - val_loss: -113453651341.0612 - val_accuracy: 0.1108\n",
      "Epoch 23/50\n",
      "1761/1761 [==============================] - 17s 10ms/step - loss: -124765230691.1437 - accuracy: 0.1326 - val_loss: -162097735805.3878 - val_accuracy: 0.1289\n",
      "Epoch 24/50\n",
      "1761/1761 [==============================] - 15s 9ms/step - loss: -176992386448.6451 - accuracy: 0.1206 - val_loss: -227853863167.4195 - val_accuracy: 0.1098\n",
      "Epoch 25/50\n",
      "1761/1761 [==============================] - 19s 11ms/step - loss: -247363010597.2152 - accuracy: 0.1377 - val_loss: -315529876003.9909 - val_accuracy: 0.1232\n",
      "Epoch 26/50\n",
      "1761/1761 [==============================] - 16s 9ms/step - loss: -339891381084.6020 - accuracy: 0.1149 - val_loss: -431108001857.0159 - val_accuracy: 0.1184\n",
      "Epoch 27/50\n",
      "1761/1761 [==============================] - 16s 9ms/step - loss: -461836250710.3510 - accuracy: 0.1466 - val_loss: -581380086154.7393 - val_accuracy: 0.1222\n",
      "Epoch 28/50\n",
      "1761/1761 [==============================] - 16s 9ms/step - loss: -619932805123.4889 - accuracy: 0.1048 - val_loss: -774625493289.2155 - val_accuracy: 0.1193\n",
      "Epoch 29/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -820450283750.2692 - accuracy: 0.1302 - val_loss: -1021291491634.5034 - val_accuracy: 0.1451\n",
      "Epoch 30/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -1077154032317.2743 - accuracy: 0.1179 - val_loss: -1331943582750.1860 - val_accuracy: 0.1384\n",
      "Epoch 31/50\n",
      "1761/1761 [==============================] - 17s 9ms/step - loss: -1397765687713.5083 - accuracy: 0.1484 - val_loss: -1720614531564.2629 - val_accuracy: 0.1270\n",
      "Epoch 32/50\n",
      "1761/1761 [==============================] - 19s 11ms/step - loss: -1800923924953.3311 - accuracy: 0.1087 - val_loss: -2201559235419.1382 - val_accuracy: 0.1527\n",
      "Epoch 33/50\n",
      "1761/1761 [==============================] - 17s 10ms/step - loss: -2293926724179.4438 - accuracy: 0.1574 - val_loss: -2795380542066.9390 - val_accuracy: 0.1384\n",
      "Epoch 34/50\n",
      "1761/1761 [==============================] - 13s 8ms/step - loss: -2906275542054.9600 - accuracy: 0.1340 - val_loss: -3518639888518.6758 - val_accuracy: 0.1051\n",
      "Epoch 35/50\n",
      "1761/1761 [==============================] - 13s 7ms/step - loss: -3649152749044.6611 - accuracy: 0.1027 - val_loss: -4396753624029.1699 - val_accuracy: 0.1337\n",
      "Epoch 36/50\n",
      "1761/1761 [==============================] - 13s 7ms/step - loss: -4539924725992.5947 - accuracy: 0.1263 - val_loss: -5459964020285.5332 - val_accuracy: 0.1479\n",
      "Epoch 37/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -5616658883709.0205 - accuracy: 0.1387 - val_loss: -6733032027904.5801 - val_accuracy: 0.1203\n",
      "Epoch 38/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -6909705187628.0469 - accuracy: 0.1535 - val_loss: -8247563497741.3516 - val_accuracy: 0.1155\n",
      "Epoch 39/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -8434960024603.3301 - accuracy: 0.0975 - val_loss: -10046001584671.3457 - val_accuracy: 0.1317\n",
      "Epoch 40/50\n",
      "1761/1761 [==============================] - 13s 8ms/step - loss: -10258852907620.8887 - accuracy: 0.1437 - val_loss: -12160199683139.3379 - val_accuracy: 0.1317\n",
      "Epoch 41/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -12386745551125.9512 - accuracy: 0.1269 - val_loss: -14646413139429.2969 - val_accuracy: 0.1108\n",
      "Epoch 42/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -14881380026450.5723 - accuracy: 0.1109 - val_loss: -17550234130752.4355 - val_accuracy: 0.1479\n",
      "Epoch 43/50\n",
      "1761/1761 [==============================] - 13s 8ms/step - loss: -17803431660439.9141 - accuracy: 0.1650 - val_loss: -20920915555799.3633 - val_accuracy: 0.1632\n",
      "Epoch 44/50\n",
      "1761/1761 [==============================] - 13s 8ms/step - loss: -21161412968122.3672 - accuracy: 0.1206 - val_loss: -24833697310176.6523 - val_accuracy: 0.0984\n",
      "Epoch 45/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -25084737033194.4844 - accuracy: 0.1334 - val_loss: -29331132938133.1875 - val_accuracy: 0.1403\n",
      "Epoch 46/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -29564558018503.0117 - accuracy: 0.1379 - val_loss: -34506194532951.0742 - val_accuracy: 0.0984\n",
      "Epoch 47/50\n",
      "1761/1761 [==============================] - 15s 8ms/step - loss: -34737977258674.8086 - accuracy: 0.1108 - val_loss: -40416168692821.9141 - val_accuracy: 0.1327\n",
      "Epoch 48/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -40623710391954.8281 - accuracy: 0.1385 - val_loss: -47165386304467.8828 - val_accuracy: 0.1451\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1761/1761 [==============================] - 14s 8ms/step - loss: -47328816443217.5547 - accuracy: 0.1533 - val_loss: -54842836555799.2188 - val_accuracy: 0.1070\n",
      "Epoch 50/50\n",
      "1761/1761 [==============================] - 14s 8ms/step - loss: -54955889486404.3281 - accuracy: 0.1121 - val_loss: -63534188182103.0781 - val_accuracy: 0.1194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x277938cd438>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_t, X_t, validation_split=0.2,\n",
    "                epochs=50,\n",
    "                batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sismc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sismc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import nltk\n",
    "import itertools\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "tokenizer = ToktokTokenizer()\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '..\\data'\n",
    "df = pd.read_parquet(path+'\\\\data_scientist_merged_01_09_2019.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Only Job Description field will be processed in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df[['id','description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_sub.drop_duplicates('id')\n",
    "df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(path+'\\\\GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    text = re.sub(pattern, \", \",text)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "# Function to get the embedding vector for n dimension, we have used \"300\"\n",
    "def get_embedding(word):\n",
    "    if word in model.wv.vocab:\n",
    "        return model[word]\n",
    "    else:\n",
    "        return np.zeros(300)\n",
    "\n",
    "def remove_embed(text):\n",
    "    filt_text = remove_stopwords(text)\n",
    "    return np.array([get_embedding(word) for word in filt_text])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sub['word_vec'] = df_sub.apply(lambda x: remove_embed(x['description']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['word_vec'].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "m=0\n",
    "l=50\n",
    "while m<len(df_sub):\n",
    "    print(m,l)\n",
    "    df_sub.iloc[m:l].to_pickle(path+'\\\\word_encoding\\\\'+str(l)+'encoded_description.pkl',protocol=2)\n",
    "    m=m+51\n",
    "    l=l+51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### test a pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(\"C:\\\\Users\\\\sismc\\\\Desktop\\\\projects\\\\documentClusteringDNN\\\\data\\\\word_encoding\\\\1937encoded_description.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
